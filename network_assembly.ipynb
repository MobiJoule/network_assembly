{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- set params ----------- #\n",
    "\n",
    "writefiles = False\n",
    "render_maps = True\n",
    "\n",
    "# buffer around input perimeter polygon\n",
    "perimeter_buffer = -3000\n",
    "\n",
    "crs_global = 4326\n",
    "crs_dem = 25832"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- init -----------\n",
    "import osmnx as ox\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from datetime import date\n",
    "import folium\n",
    "from shapely.geometry import LineString, MultiLineString\n",
    "import plotly.graph_objects as go\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from shapely import wkb\n",
    "from shapely.geometry import Point\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from shapely.geometry import box\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# custom skip magic\n",
    "from IPython.core.magic import register_cell_magic\n",
    "@register_cell_magic\n",
    "def skip(line, cell):\n",
    "    pass  # Ignores execution\n",
    "\n",
    "data_dir = Path.cwd().parent / '10_data' \n",
    "\n",
    "\n",
    "# ----------- attributes to retrieve -----------\n",
    "ox.settings.useful_tags_way = [\n",
    "    'highway', 'lanes', \n",
    "    'surface', 'lit', 'maxspeed', 'landuse', 'junction',\n",
    "    'oneway', 'oneway:bicycle', 'bicycle', \n",
    "    'cycleway',  \n",
    "    \n",
    "    'cycleway:right', 'cycleway:left', 'cycleway:both',\n",
    "    'cycleway:right:oneway', 'cycleway:left:oneway',\n",
    "\n",
    "]\n",
    "\n",
    "ox.settings.useful_tags_node = [\n",
    "    'asl', 'bicycle_parking', 'cycleway'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o:\\Public\\4233-82676-BIKELONGER-persondata\\PhD_uelii\\01_data\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------- load perimeter ----------#\n",
    "polygon = gpd.read_file(data_dir / \"city_perimeters/polygon_copenhagen.geojson\").to_crs(25832)\n",
    "polygon = polygon.buffer(perimeter_buffer).to_crs(4326)\n",
    "\n",
    "# Get OSM full network\n",
    "cycle_graph = ox.graph_from_polygon(polygon.union_all(), network_type=\"all\", simplify=False)\n",
    "\n",
    "# Add bearings and edge lengths\n",
    "cycle_graph = ox.add_edge_bearings(cycle_graph)\n",
    "cycle_graph = ox.distance.add_edge_lengths(cycle_graph)\n",
    "\n",
    "# Convert to GeoDataFrames\n",
    "cycle_nodes, cycle_edges = ox.graph_to_gdfs(cycle_graph, nodes=True, edges=True)\n",
    "\n",
    "# number rounding\n",
    "cycle_edges[\"bearing\"] = cycle_edges[\"bearing\"].round()\n",
    "cycle_edges[\"length\"] = cycle_edges[\"length\"].round(2)\n",
    "\n",
    "\n",
    "# ----------- filter for highway keys -----------\n",
    "\n",
    "cycle_edges = cycle_edges[(\n",
    "        cycle_edges['highway'].isin([\n",
    "            \"primary\", \"primary_link\",\n",
    "            \"secondary\", \"secondary_link\", \n",
    "            \"tertiary\", \"tertiary_link\",\n",
    "            \"residential\", \"living_street\", \"service\", \n",
    "            \"path\", \"unclassified\", \"track\", \n",
    "            \"road\", \n",
    "            \"cycleway\",\n",
    "            \"pedestrian\", \"footway\"])  |\n",
    "    cycle_edges['cycleway'].isin([\"lane\", \"shared_lane\", \"share_busway\", \"track\" ]) |\n",
    "    cycle_edges['cycleway:right'].isin([\"lane\", \"shared_lane\", \"share_busway\", \"track\" ]) |\n",
    "    cycle_edges['cycleway:both'].isin([\"lane\", \"shared_lane\", \"share_busway\", \"track\" ]) |\n",
    "    cycle_edges['cycleway:left'].isin([\"lane\", \"shared_lane\", \"share_busway\", \"track\" ])\n",
    ")]\n",
    "\n",
    "\n",
    "# Reset Indices\n",
    "cycle_edges.reset_index(inplace = True, drop = False)\n",
    "cycle_nodes.reset_index(inplace = True, drop = False)\n",
    "\n",
    "# drop OSMID because it's of no practical use\n",
    "cycle_edges = cycle_edges.drop(columns = 'osmid')\n",
    "\n",
    "\n",
    "# ----------- replace nan strings with nan -----------\n",
    "cycle_edges.replace(\"nan\", np.nan, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ---- select links ----\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# init temp column to indicate manually reversed links\n",
    "cycle_edges['reversed_manually'] = False\n",
    "\n",
    "def flip_link(row):\n",
    "    reversed_row = row.copy()\n",
    "    # Swap u and v\n",
    "    reversed_row['u'], reversed_row['v'] = row['v'], row['u']\n",
    "    # Invert bearing\n",
    "    reversed_row['bearing'] = (row['bearing'] + 180) % 360\n",
    "    # Invert reversed boolean\n",
    "    reversed_row['reversed'] = not row['reversed']\n",
    "    # swap left / right cycleway\n",
    "    reversed_row['cycleway:left'], reversed_row['cycleway:right'] = reversed_row['cycleway:right'], reversed_row['cycleway:left']\n",
    "    # Reverse geometry\n",
    "    reversed_row['geometry'] = LineString(row['geometry'].coords[::-1])\n",
    "    # Indicate newly created twin\n",
    "    reversed_row['reversed_manually'] = True\n",
    "    return reversed_row\n",
    "\n",
    "\n",
    "# ----------- function to select links conditionally -----------\n",
    "\n",
    "\n",
    "def select_links(link):\n",
    "    out = []\n",
    "    # for oneway links with bicycle counterflow, insert reverse link (will be filtered for duplicates later on)\n",
    "    if link['oneway']: #and link['oneway:bicycle'] == 'no'\n",
    "        reverse_link = flip_link(link)\n",
    "        out.append(reverse_link)\n",
    "    out.append(link)       \n",
    "    return out\n",
    "\n",
    "# run function\n",
    "selected_rows = []\n",
    "for _, row in cycle_edges.iterrows():\n",
    "    result = select_links(row)\n",
    "    if result:\n",
    "        selected_rows.extend(result)\n",
    "\n",
    "cycle_edges = gpd.GeoDataFrame(selected_rows, geometry='geometry', crs=crs_global)\n",
    "\n",
    "# ----------- determine most relevant cycleway type -----------\n",
    "# source hierarchy is \n",
    "# 1 cycleway - 48k entries\n",
    "# 2 cycleway:both - 37k entries\n",
    "# 3 cycleway:right - 14k entries \n",
    "# - bicycle\n",
    "\n",
    "def assign_main_cycleway_type(link):\n",
    "    # 1 highway = cycleway\n",
    "    if link['highway'] == \"cycleway\":\n",
    "            main_cycleway_type = 'cycleway'\n",
    "    # 2 cycleway key \n",
    "    elif pd.notna(link['cycleway']) and link['cycleway'] not in [\"no\", \"nan\"]:\n",
    "        main_cycleway_type = str(link['cycleway']).replace(\"opposite_\", \"\")\n",
    "    # 3 cycleway:both key \n",
    "    elif pd.notna(link['cycleway:both']) and link['cycleway:both'] not in [\"no\", \"nan\"]:\n",
    "        main_cycleway_type = str(link['cycleway:both']).replace(\"opposite_\", \"\")\n",
    "    # 4 cycleway:right key\n",
    "    elif pd.notna(link['cycleway:right']) and link['cycleway:right'] not in [\"no\", \"nan\"]:\n",
    "        main_cycleway_type = str(link['cycleway:right']).replace(\"opposite_\", \"\")\n",
    "    # X cycling on pedestrian ways ( but not stairs / steps )\n",
    "    elif link['highway'] in ['pedestrian', 'footway', 'path']:\n",
    "            # Xa permitted implicitly. even if \"bicycle = no\" is set, this is implemented\n",
    "            # inconsistently and not followed by observed cyclist tracks\n",
    "            if link['bicycle'] in ['no']:\n",
    "                main_cycleway_type = \"shared_pedestrian_disallowed\"\n",
    "            else:\n",
    "                main_cycleway_type = \"shared_pedestrian\"\n",
    "    # X edge cases : no cycleway assigned but an explicitly permitted \"bicycle\" category\n",
    "    elif pd.notna(link['bicycle']) and link['bicycle'] not in ['no', 'use_sidepath']:\n",
    "        main_cycleway_type = link['bicycle']\n",
    "        # double check, fallback value : \"permitted\"\n",
    "        # if 'designated', per osm guidelines, there exists a cycleway attribute though\n",
    "    # X cycling on shared lane with motor traffic\n",
    "    elif link['highway'] not in ['pedestrian', 'path', 'footway', 'cycleway']:\n",
    "        main_cycleway_type = \"unguided\"\n",
    "    \n",
    "    # final catcher\n",
    "    else:\n",
    "        main_cycleway_type = \"undefined\"\n",
    "\n",
    "    # reassign after loop:\n",
    "    if main_cycleway_type in ['designated', 'destination', 'dismount', 'permissive', 'private', 'yes']:\n",
    "        main_cycleway_type = 'unguided_but_permitted_explicitly'\n",
    "    if main_cycleway_type == \"shared_lane\":\n",
    "        main_cycleway_type = \"unguided\"\n",
    "    if main_cycleway_type in ['construction', 'crossing', 'link']:\n",
    "        main_cycleway_type = 'lane'\n",
    "    if main_cycleway_type in ['use_sidepath', 'separate','seperate', 'use_seperate']:\n",
    "        main_cycleway_type = 'separate_track_indicated'\n",
    "    if main_cycleway_type == 'share_busway':\n",
    "        main_cycleway_type = 'shared_buslane'\n",
    "    if main_cycleway_type == 'shared':\n",
    "        main_cycleway_type = 'unguided'    \n",
    "    if main_cycleway_type == 'opposite':\n",
    "        main_cycleway_type = 'unguided'    \n",
    "    if main_cycleway_type == 'shoulder':\n",
    "        main_cycleway_type = 'unguided'     \n",
    "    return main_cycleway_type\n",
    "\n",
    "cycle_edges['cycleway_master'] = cycle_edges.apply(assign_main_cycleway_type, axis=1)\n",
    "\n",
    "# ----------- turn into numbered item for possible comparisons -----------\n",
    "# define hierarchy from most to least important\n",
    "cycle_edges['cycleway_master'] = cycle_edges['cycleway_master'].replace({\n",
    "    'cycleway': '1_cycleway',\n",
    "    'track': '2a_track',\n",
    "    'separate_track_indicated': '2b_separate_track_indicated',\n",
    "    'lane': '3_lane',\n",
    "    'shared_buslane': '4_shared_buslane',\n",
    "    'unguided_but_permitted_explicitly': '5_unguided_but_permitted_explicitly',\n",
    "    'shared_pedestrian': '6a_shared_pedestrian',\n",
    "    'shared_pedestrian_disallowed': '6b_shared_pedestrian_disallowed',\n",
    "    'unguided': '7_unguided'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign nodes \"is_junction\" if 3 or more edges connected\n",
    "# to differentiate between geometric nodes and true nodes\n",
    "\n",
    "# combine u and v into one list of (node, neighbor)\n",
    "pairs = pd.concat([\n",
    "    cycle_edges[['u', 'v']],\n",
    "    cycle_edges[['v', 'u']].rename(columns={'v': 'u', 'u': 'v'})\n",
    "]).drop_duplicates()\n",
    "\n",
    "# count how many unique neighbors each node has\n",
    "deg = pairs.groupby('u')['v'].nunique()\n",
    "\n",
    "cycle_nodes_assigned = cycle_nodes.copy()\n",
    "cycle_nodes_assigned['is_junction'] = cycle_nodes_assigned['osmid'].map(deg).fillna(0).ge(3)\n",
    "\n",
    "# keep only nodes referenced in edges\n",
    "cycle_nodes_assigned = cycle_nodes_assigned[\n",
    "    cycle_nodes_assigned['osmid'].isin(cycle_edges['u']) |\n",
    "    cycle_nodes_assigned['osmid'].isin(cycle_edges['v'])\n",
    "]\n",
    "\n",
    "# ----------- enrich edges with END NODE data (attributes + is_junction) ----------- #\n",
    "end_node_attrs = cycle_nodes_assigned.copy()\n",
    "end_node_attrs = end_node_attrs.add_prefix('end_node_')\n",
    "end_node_attrs = end_node_attrs.rename(columns={\n",
    "    'end_node_osmid': 'v',\n",
    "    'end_node_highway': 'end_node_amenity'\n",
    "}).drop(columns=['end_node_x', 'end_node_y', 'end_node_geometry'])\n",
    "\n",
    "cycle_edges = cycle_edges.merge(end_node_attrs, on='v', how='left')\n",
    "\n",
    "# ----------- drop duplicates created in reversing links manually ----------- #\n",
    "dupe_mask = cycle_edges.duplicated(subset=['u', 'v', 'key'], keep=False)\n",
    "cycle_edges = cycle_edges[\n",
    "    ~dupe_mask | (dupe_mask & (cycle_edges['reversed_manually'] != True))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- cluster intersections -----------\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "eps = 20\n",
    "\n",
    "true_fork_nodes = cycle_nodes_assigned[cycle_nodes_assigned['is_junction']].to_crs(crs_dem)\n",
    "#coords = [[cycle_nodes_pruned.geometry.x, cycle_nodes_pruned.geometry.y]]\n",
    "coords = np.array(list(zip(true_fork_nodes.geometry.x, true_fork_nodes.geometry.y)))\n",
    "\n",
    "# DBSCAN\n",
    "dbscan = DBSCAN(eps=eps, min_samples=2)\n",
    "cluster_labels = dbscan.fit_predict(coords)\n",
    "\n",
    "# Update cluster labels\n",
    "\n",
    "true_fork_nodes['node_cluster'] = cluster_labels\n",
    "\n",
    "intersection_cluster_key = true_fork_nodes[['osmid', 'node_cluster' ]]\n",
    "\n",
    "# Group by 'cluster' and compute centroid of each group\n",
    "true_fork_centroids = (\n",
    "    true_fork_nodes\n",
    "    .dissolve(by='node_cluster')  # merges by cluster\n",
    "    .centroid\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "true_fork_centroids = gpd.GeoDataFrame(true_fork_centroids, geometry=0, crs=true_fork_nodes.crs)\n",
    "true_fork_centroids = true_fork_centroids.rename(columns={0: 'geometry'}).set_geometry(\"geometry\")\n",
    "\n",
    "\n",
    "# ----------- get stop cluster information -----------\n",
    "stop_clusters = pd.read_parquet('data/hovding_stop_clusters/hovding_stop_clusters.parquet')\n",
    "stop_clusters['geometry'] = [Point(xy) for xy in zip(stop_clusters['longitude'], stop_clusters['latitude'])]\n",
    "stop_clusters = gpd.GeoDataFrame(stop_clusters, geometry='geometry', crs=crs_global).to_crs(crs_dem).drop(columns = ['cluster', 'latitude', 'longitude', 'intersection_id'])\n",
    "\n",
    "\n",
    "\n",
    "# ----------- join stop clusters to intersection cluster centroid by nearest -----------\n",
    "# Spatial join by nearest within 40 meters\n",
    "intersections_enriched = gpd.sjoin_nearest(\n",
    "    true_fork_centroids,\n",
    "    stop_clusters,\n",
    "    how='left',\n",
    "    max_distance=40,\n",
    "    distance_col='dist'\n",
    ").drop(columns = ['index_right', 'geometry'])\n",
    "    \n",
    "intersections_enriched['dist'] = intersections_enriched['dist'].round(1)\n",
    "\n",
    "intersections_enriched = intersections_enriched.merge(intersection_cluster_key, how = 'right', on = 'node_cluster')\n",
    "\n",
    "cycle_nodes_assigned = cycle_nodes_assigned.merge(intersections_enriched, how = 'left', on= 'osmid')\n",
    "\n",
    "\n",
    "cycle_edges = cycle_edges.merge(cycle_nodes_assigned[[\"osmid\", \"ratio_stopped\", \"mean_duration_stopped\", \"red_cycle_95pct\"]], how = \"left\", \n",
    "                                          left_on = \"v\",\n",
    "                                          right_on = \"osmid\",\n",
    "                                          ).drop(columns = \"osmid\")\n",
    "\n",
    "cycle_edges = cycle_edges.rename(columns = {'ratio_stopped' : 'end_node_ratio_stopped',\n",
    "                                                    'mean_duration_stopped' : 'end_node_mean_duration_stopped',\n",
    "                                                    'red_cycle_95pct' : 'end_node_red_phase_estimate'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- additions through corin : booleans -----------\n",
    "\n",
    "cycle_edges['highway_is_pedestrian'] = ((cycle_edges['highway'] == 'pedestrian') | \n",
    "                                        (cycle_edges['highway'] == 'footway') | \n",
    "                                        (cycle_edges['highway'] == 'path')                                       \n",
    "                                        )\n",
    "\n",
    "cycle_edges['cycletrack_assumed_separate'] = (\n",
    "    ((cycle_edges['cycleway:right'] == 'separate') & (~cycle_edges['reversed'])) |\n",
    "    ((cycle_edges['cycleway:left'] == 'separate') & (cycle_edges['reversed']))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# ---- network ID looup ----\n",
    "# -----------------------------------------------------------------------------\n",
    "# Create unique network_id\n",
    "cycle_edges[\"network_id\"] = cycle_edges.index\n",
    "cols = [\"network_id\"] + [col for col in cycle_edges.columns if col != \"network_id\"]\n",
    "cycle_edges = cycle_edges[cols]\n",
    "\n",
    "\n",
    "# ----------- lookup table -----------\n",
    "lookup_table = cycle_edges[[\"network_id\", \"u\", \"v\", \"key\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## match DTM to points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "\n",
    "import rasterio\n",
    "from shapely.geometry import box\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ---- create DTM boundary index ----\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "tifcount = 0\n",
    "dem_dir = Path(\"data/dem\")\n",
    "records = []\n",
    "\n",
    "for fp in dem_dir.glob(\"*.tif\"):\n",
    "    with rasterio.open(fp) as src:\n",
    "        b = src.bounds\n",
    "        records.append({\n",
    "            \"path\": str(fp.resolve()),\n",
    "            \"crs\": src.crs.to_string(),\n",
    "            \"minx\": b.left,\n",
    "            \"miny\": b.bottom,\n",
    "            \"maxx\": b.right,\n",
    "            \"maxy\": b.top\n",
    "        })\n",
    "    tifcount += 1\n",
    "    if tifcount % 10 == 0:\n",
    "        print(f'processed {tifcount} geoTIFs.')\n",
    "\n",
    "pd.DataFrame(records).to_csv(dem_dir / \"dem_index.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ---- match DTMs to tiles in batches ----\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "batchsize = 20\n",
    "dem_dir = Path(\"data/dem\")\n",
    "\n",
    "#gdf = cycle_nodes_assigned.to_crs(crs_dem)\n",
    "gdf = cycle_nodes.to_crs(crs_dem)\n",
    "\n",
    "def tile_bounds(bounds, size=1000):\n",
    "    minx, miny, maxx, maxy = bounds\n",
    "    x_coords = np.arange(minx, maxx, size)\n",
    "    y_coords = np.arange(miny, maxy, size)\n",
    "    tiles = [\n",
    "        box(x, y, x + size, y + size)\n",
    "        for x in x_coords for y in y_coords\n",
    "    ]\n",
    "    return tiles\n",
    "\n",
    "\n",
    "# Paths\n",
    "save_path = Path(\"out/altitudes_dem.parquet\")\n",
    "dem_index = pd.read_csv(dem_dir / \"dem_index.csv\")\n",
    "\n",
    "# Load or initialize elevation dataframe\n",
    "if save_path.exists():\n",
    "    gdf_elevations = gpd.read_parquet(save_path)\n",
    "    ele_done = gdf_elevations[gdf_elevations[\"altitude_dem\"].notna()]\n",
    "    ele_todo = gdf_elevations[gdf_elevations[\"altitude_dem\"].isna()]\n",
    "\n",
    "else:\n",
    "    ele_todo = gdf[['osmid', 'x', 'y', 'geometry']].copy()\n",
    "    ele_todo[\"altitude_dem\"] = np.nan\n",
    "    ele_done = gpd.GeoDataFrame()\n",
    "\n",
    "\n",
    "tile_counter = 0\n",
    "\n",
    "tiles = tile_bounds(ele_todo.total_bounds, size=1000)\n",
    "tile_gdf = gpd.GeoDataFrame(geometry=tiles, crs=gdf.crs)\n",
    "\n",
    "for tile in tile_gdf.geometry:\n",
    "    tile_bounds = tile.bounds\n",
    "\n",
    "    # Points within current tile\n",
    "    subset = ele_todo[ele_todo.geometry.within(tile)]\n",
    "    if subset.empty:\n",
    "        continue\n",
    "\n",
    "    # DEMs intersecting tile\n",
    "    overlapping_dems = dem_index[\n",
    "        (dem_index.minx < tile_bounds[2]) &\n",
    "        (dem_index.maxx > tile_bounds[0]) &\n",
    "        (dem_index.miny < tile_bounds[3]) &\n",
    "        (dem_index.maxy > tile_bounds[1])\n",
    "    ]\n",
    "\n",
    "    for _, dem in overlapping_dems.iterrows():\n",
    "        with rasterio.open(Path(dem[\"path\"])) as src:\n",
    "            dem_bounds = box(dem.minx, dem.miny, dem.maxx, dem.maxy)\n",
    "            points_in_dem = subset[subset.geometry.within(dem_bounds)]\n",
    "            if points_in_dem.empty:\n",
    "                continue\n",
    "\n",
    "            coords = [(pt.x, pt.y) for pt in points_in_dem.geometry]\n",
    "            values = [val[0] for val in src.sample(coords)]\n",
    "            dn = src.nodata\n",
    "\n",
    "            elev = np.round(values, 3)\n",
    "            elev = [np.nan if v == dn else v for v in elev]\n",
    "            ele_todo.loc[points_in_dem.index, \"altitude_dem\"] = elev\n",
    "\n",
    "    tile_counter += 1\n",
    "\n",
    "    # Save every x tiles\n",
    "    if tile_counter % batchsize == 0:\n",
    "        ele_out = pd.concat([ele_done, ele_todo], ignore_index=True)\n",
    "        ele_out.to_parquet(save_path, index=False)\n",
    "        print(f\"Saved after {tile_counter} tiles\")\n",
    "\n",
    "# Final save\n",
    "ele_out.to_parquet(save_path, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = gpd.read_parquet('data/dem/matched_dem_copenhagen.parquet')\n",
    "\n",
    "# Merge for ele_orig\n",
    "cycle_edges = cycle_edges.merge(\n",
    "    dtm[['osmid', 'altitude_dem']],\n",
    "    how='left',\n",
    "    left_on='u',\n",
    "    right_on='osmid'\n",
    ").rename(columns={'altitude_dem': 'ele_orig'}).drop(columns='osmid')\n",
    "\n",
    "# Merge for ele_dest\n",
    "cycle_edges = cycle_edges.merge(\n",
    "    dtm[['osmid', 'altitude_dem']],\n",
    "    how='left',\n",
    "    left_on='v',\n",
    "    right_on='osmid'\n",
    ").rename(columns={'altitude_dem': 'ele_dest'}).drop(columns='osmid')\n",
    "\n",
    "cycle_edges['gradient'] = (cycle_edges['ele_dest'] - cycle_edges['ele_orig']) / cycle_edges['length']\n",
    "\n",
    "\n",
    "cycle_edges['ele_orig'] = cycle_edges['ele_orig'].round(2)\n",
    "cycle_edges['ele_dest'] = cycle_edges['ele_dest'].round(2)\n",
    "cycle_edges['gradient'] = cycle_edges['gradient'].round(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate links\n",
    "\n",
    "cycle_edges = cycle_edges.drop_duplicates(subset=['u', 'v', 'key'], keep='first')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_edges = cycle_edges.astype({\n",
    "    'u': 'int64',\n",
    "    'v': 'int64',\n",
    "    'key': 'Int8',\n",
    "    'highway': 'string',\n",
    "    'lanes': 'Int8',\n",
    "    'surface': 'string',\n",
    "    'lit': 'string',\n",
    "    'maxspeed': 'Int16',\n",
    "    'oneway': 'bool',\n",
    "    'reversed': 'bool',\n",
    "    'reversed_manually': 'bool',\n",
    "    'cycleway': 'string',\n",
    "    'bicycle': 'string',\n",
    "    'junction': 'string',\n",
    "    'oneway:bicycle': 'string',\n",
    "    'cycleway:both': 'string',\n",
    "    'cycleway:left': 'string',\n",
    "    'cycleway:right': 'string',\n",
    "    'cycleway:left:oneway': 'string',\n",
    "    'cycleway_master': 'string',\n",
    "    'end_node_street_count': 'int64',\n",
    "    'end_node_is_junction': 'bool',\n",
    "    'end_node_ratio_stopped': 'float32',\n",
    "    })\n",
    "\n",
    "cycle_edges['length'] = cycle_edges['length'].round(2).astype('float32')\n",
    "cycle_edges['bearing'] = cycle_edges['bearing'].round().astype('Int16')\n",
    "cycle_edges['end_node_red_phase_estimate'] = cycle_edges['end_node_red_phase_estimate'].round().astype('Int16')\n",
    "cycle_edges['end_node_ratio_stopped'] = cycle_edges['end_node_ratio_stopped'].round(4).astype('float32')\n",
    "cycle_edges['end_node_mean_duration_stopped'] = cycle_edges['end_node_mean_duration_stopped'].round(2).astype('float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.options.io_engine = \"pyogrio\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# ---- write files ----\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "if writefiles:\n",
    "        \n",
    "    #today_str = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    today_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    cycle_edges_out_extended = cycle_edges.to_crs(32632)\n",
    "    cycle_edges_out_short = cycle_edges_out_extended[[\"network_id\", \"highway\", \"cycleway_master\", \"geometry\"]]\n",
    "\n",
    "    # ----------- parquet ----------- # \n",
    "    #cycle_edges_out_extended.to_parquet(f\"out/osm_nodes_MobiJoule_{today_str}.parquet\")\n",
    "    #cycle_edges_out_short.to_parquet(f\"out/osm_edges_MobiJoule_{today_str}_short.parquet\")\n",
    "\n",
    "    # ----------- gpkg ----------- # \n",
    "    cycle_edges_out_extended.to_file(f\"out/osm_edges_MobiJoule_{today_str}.gpkg\", layer='cycle_edges', driver=\"GPKG\")\n",
    "    #cycle_edges_out_short.to_file(f\"out/osm_edges_MobiJoule_{today_str}_short.gpkg\", layer='cycle_edges', driver=\"GPKG\")\n",
    "    \n",
    "    # ----------- lookup table ----------- #  \n",
    "    lookup_table.to_csv(f\"out/osm_edges_MobiJoule_{today_str}_id_lookup.csv\", index=False)\n",
    "        \n",
    "        \n",
    "    # csv\n",
    "    #cycle_edges_csv = cycle_edges.drop(columns = \"geometry\")\n",
    "    #cycle_edges_csv.to_csv(f\"out/osm_edges_MobiJoule_{today_str}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- plot intersection clusters -----------\n",
    "\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import random\n",
    "import matplotlib.colors as mcolors\n",
    "import itertools\n",
    "\n",
    "\n",
    "# Filter out rows with null node_cluster and convert CRS\n",
    "gdf_plot = cycle_nodes_assigned[cycle_nodes_assigned['node_cluster'].notna()].to_crs(4326)\n",
    "\n",
    "# Ensure cluster values are strings\n",
    "\n",
    "# Assign colors\n",
    "base_colors = list(mcolors.CSS4_COLORS.values())\n",
    "color_cycle = itertools.cycle(base_colors)\n",
    "clusters = gdf_plot['node_cluster'].unique()\n",
    "\n",
    "cluster_colors = {\n",
    "    cluster: 'lightgrey' if cluster == -1 else next(color_cycle)\n",
    "    for cluster in clusters\n",
    "}\n",
    "\n",
    "\n",
    "# Center map on data\n",
    "center = gdf_plot.union_all().centroid\n",
    "m = folium.Map(location=[center.y, center.x], zoom_start=12)\n",
    "\n",
    "# Add points to map with color and tooltip\n",
    "for _, row in gdf_plot.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row.geometry.y, row.geometry.x],\n",
    "        radius=4,\n",
    "        color=cluster_colors[row['node_cluster']],\n",
    "        fill=False,\n",
    "        fill_opacity=0.8,\n",
    "        tooltip=f\"Cluster: {row['node_cluster']}\"\n",
    "    ).add_to(m)\n",
    "\n",
    "m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- plot altitudes -----------\n",
    "\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "from folium import CircleMarker\n",
    "\n",
    "gdf_plot = gdf[pd.notna(gdf['altitude_dem'])].to_crs(crs_global)\n",
    "# Normalize altitude values for color mapping\n",
    "min_alt = gdf_plot['altitude_dem'].min()\n",
    "max_alt = gdf_plot['altitude_dem'].max()\n",
    "gdf_plot['altitude_norm'] = (gdf_plot['altitude_dem'] - min_alt) / (max_alt - min_alt)\n",
    "\n",
    "# Define a function to convert normalized altitude to color (blue to red gradient)\n",
    "def altitude_to_color(norm_val):\n",
    "    r = int(255 * norm_val)\n",
    "    b = int(255 * (1 - norm_val))\n",
    "    return f'#{r:02x}00{b:02x}'\n",
    "\n",
    "# Create folium map centered on the data\n",
    "center = [gdf_plot.geometry.y.mean(), gdf_plot.geometry.x.mean()]\n",
    "m = folium.Map(location=center, zoom_start=10)\n",
    "\n",
    "# Add points\n",
    "for _, row in gdf_plot.iterrows():\n",
    "    color = altitude_to_color(row['altitude_norm'])\n",
    "    CircleMarker(\n",
    "        location=[row.geometry.y, row.geometry.x],\n",
    "        radius=5,\n",
    "        color=color,\n",
    "        fill=True,\n",
    "        fill_opacity=0.8,\n",
    "        tooltip=str(row['altitude_dem'])\n",
    "\n",
    "    ).add_to(m)\n",
    "\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
